<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Research</title>
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="" name="keywords">
  <meta content="" name="description">

  <!-- Favicons -->
  <link href="img/cube.png" rel="icon">
  <link href="img/cube.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700|Raleway:400,700&display=swap"
    rel="stylesheet">

  <!-- Bootstrap CSS File -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="vendor/line-awesome/css/line-awesome.min.css" rel="stylesheet">
  <link href="vendor/aos/aos.css" rel="stylesheet">
  <link href="vendor/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="css/style.css" rel="stylesheet">

  <!-- =======================================================
    Template Name: MyPortfolio
    Template URL: https://bootstrapmade.com/myportfolio-bootstrap-portfolio-website-template/
    Author: BootstrapMade.com
    Author URL: https://bootstrapmade.com/
  ======================================================= -->
</head>

<body>


  <div class="collapse navbar-collapse custom-navmenu" id="main-navbar">
    <div class="container py-2 py-md-5">
      <div class="row align-items-start">
        <div class="col-md-2">
          <ul class="custom-menu">
            <li><a href="index.html">Home</a></li>
            <li class="active"><a href="about.html">About Me</a></li>
            <li><a href="skills.html">Skills</a></li>
            <li><a href="works.html">Projects</a></li>
          </ul>
        </div>
        <div class="col-md-6 d-none d-md-block  mr-auto">

        </div>
        <div class="col-md-4 d-none d-md-block">
          <h3>Contact Me!</h3>
          <p>I am currently looking for new opportunities! <br> <a href="#">alex@shackleton.com</a></p>
        </div>
      </div>

    </div>
  </div>

  <nav class="navbar navbar-light custom-navbar">
    <div class="container">
      <a class="navbar-brand" href="index.html">Portfolio.</a>

      <a href="#" class="burger" data-toggle="collapse" data-target="#main-navbar">
        <span></span>
      </a>

    </div>
  </nav>



  <main id="main">

    <div class="site-section">
      <div class="container">
        <div class="row mb-4 align-items-center">
          <div class="col-md-6" data-aos="fade-up">

            <h2>Speech Classification Research</h2>
            <p>Developing a Speech Interface for use in Assistive Service Robots.</p>
            <p>This research was conducted as part of my engineering masters program and the continuation of work begun
              during a summer internship.</p>
          </div>


        </div>
      </div>

      <div class="site-section pb-0">
        <div class="container">
          <div class="row align-items-stretch">
            <div class="col-md-8" data-aos="fade-up">
              <img src="img/research.png" alt="Image" class="img-fluid">
            </div>
            <div class="col-md-3 ml-auto" data-aos="fade-up" data-aos-delay="100">
              <div class="sticky-content">
                <h3 class="h3">Research Focus</h3>
                <p class="mb-4"><span class="text-muted">The focus of this research was to develop a direct speech
                    classifier.</span></p>

                <div class="mb-5">
                  <p>This is module that distinguishes between speech directed at the robot and other environmental
                    noises.</p>

                </div>


                <h4 class="h4 mb-3">What I did</h4>
                <ul class="list-unstyled list-line mb-5">
                  <li>Comprehensive review of the state of the art.</li>
                  <li>Developed ML model for classifiation.</li>
                  <li>Complied a database for training, testing and vaildation.</li>
                  <li>Benchmarked performance against existing solutions.</li>
                </ul>

              </div>

            </div>
          </div>

        </div>
      </div>
    </div>

    <div class="site-section">
      <div class="container">
        <div class="row mb-4 align-items-center">
          <div class="col-md-12" data-aos="fade-up">
            <h3 class="h3">Problem Area</h3>
            <p class="mb-4"><span class="text-muted">The worlds ageing population is increasing at a
                dramatic rate....</span></p>
            <p>With the expected increase in the number of people over the age of 65, comes a need for more
              facilities to assist them in living independent lives. The current model of the care industry
              is not equipped to handle the impending surge in demand, so the sector is crying out for
              innovation. Assistive service robots may be part of the solution to this problem. There needs
              to be a way of controlling these devices and given the target users, voice control would
              appear the best option for a control interface.</p>
          </div>
          <div class="col-md-12" data-aos="fade-up">
            <h3 class="h3">Stage 1:</h3>
            <p class="mb-4"><span class="text-muted">Speech Processing.</span></p>
            <p>The first thing that needed to be decided on was a metric to judge the sound samples on.
              Through an extensive literature multiple speech properties were examined and compared until
              finally I settled on using Mel Frequency Spectrograms. It seemed like the perfect choice as
              the mel scale aplfies frequencies associated with human voice and the image based nature of
              the spectrogram made for easy integration into the CNN.
              Audio clips would be fed into a script to split the audio files in 4 second chunks.This
              strayed from the norm as sounds are usually analyzed in much shorter windows ( < 250ms). However I wasn't
                interested in the content of the speech (i.e exactly what someone was saying), just in the presence of
                speech in a sample so I did not need the same level of fidelity. Then each clip was converted from a wav
                file to a Mel Spectrogram using the Librosa library for Python.</p>
          </div>
          <div class="col-md-12" data-aos="fade-up">
            <h3 class="h3">Stage 2:</h3>
            <p class="mb-4"><span class="text-muted">Creating the Dataset.</span></p>
            <p>One major issue I found with previous research into speech classification with the size and
              quality of the datasets used. A lot of speech recognition models are trained on relatively
              small, clean datasets in laboratory condition. While this can be great for proof of concept,
              my research was more focused on on creating something to be used in a real-world setting
              therefore creating my own database was an essential part of the process.
              I used subsets of Google's AudioSet and the UrbanSound8K dataset along with field recordings
              in order to try and create a robust recognition model. Podcasts , Audiobooks and actual
              recordings of one sided conversations were used for the samples of direct speech. Ambient
              sounds such as kitchen noises, field recording of libraries ,cafes and hallways and other
              environmental sounds clips were used as the non speech classes. I also mixed speech and non
              speech samples together to varying degrees in order to discourage the model from overfitting
              to the training data.
              The dataset consisited of 20 hours of audio files, 10 hours of speech (50/50 male/female
              voices) and 10 hours of environmental noise (30% included some level of background
              coversation).</p>
            <h3 class="h3">Stage 3:</h3>
            <p class="mb-4"><span class="text-muted">Model Devlopment.</span></p>
            <p>First step in model development was choosing a suitable benchmark. Since using CNNâ€™s for
              speech classification was a relatively novel approach at the time there weren't many existing
              models that I could use freely for my research. Therefore I chose to split the benchmarking
              process into two sections; the application and the technology.
              The WebRTC VAD (voice activity detection) algorithm was chosen as the benchmark mark for my
              models performance at completing its classification task. The WebRTC model is considered one
              of the gold standards in Voice Activity Detection so it was an obvious choice to compare
              against.However it runs off completely different input parameters and uses a statistically
              model rather than and a neural network therefore I would have have to chose another model for
              comparison to see how well it was implemented. I chose both the ResNet 50 and VGG 19 for this
              purpose as they are well established open sourced image classification models . Using transfer
              learning I was able to adjust the model weights to fit my purpose using my new dataset.
              The custom convolutional neural network that was developed as part of this research combined
              the strived to both be light weight, like the WebRTC, so it could be used on smaller embedded
              systems but still mretain some of the powerful pattern recogniton adapibilty of the CNNs.

            </p>
            <h3 class="h3">Stage 4:</h3>
            <p class="mb-4"><span class="text-muted">Testing and Analysis.</span></p>
            <p>For the testing the dataset was given a 70/20/10 split. 70% being used model training, 20%
              for validation and the remaining 10% remaining unseen by the model to ensure fair testing.
              Each model also was put through 3 classification tasks Binary(Speech/NonSpeech) 3 Class with
              added the background speech class and 6 Class in which the background noise was broken up into
              several subsections. The models computation time was also recorded.
              The models precision and recall were used as points of comparison. Precision being how many
              many times it correctly identified a sample and recall describing how well it could recognise
              a particular class. Both were then combined to get a full picture of each models accuracy.
              The neural networks were further dissected with layer activation information being extracted.
              This could allowed me to take a peek under the hood of these neural networks and get an idea
              of what patterns and feature were causing each layer to activate ,thus how the model was
              making its classification decisions.



            </p>
          </div>
        </div>
        <div class="site-section pb-0">
          <div class="container">
            <div class="row justify-content-center text-center mb-4">
              <div class="col-5">
                <h3 class="h3 heading">More Projects</h3>

              </div>
            </div>

            <div class="row" data-aos="fade-up" data-aos-delay="200">
              <div class="item design col-sm-6 col-md-4 col-lg-4 mb-4">
                <a href="belu.html" class="item-wrap fancybox">
                  <div class="work-info">
                    <h3>BÃ©lÃº Solutions</h3>
                    <span>Co-Founder</span>
                  </div>
                  <img class="img-fluid" src="img/beluicon.png">
                </a>
              </div>
              <div class="item web col-sm-6 col-md-4 col-lg-4 mb-4">
                <a href="mb.html" class="item-wrap fancybox">
                  <div class="work-info">
                    <h3>The Mouldy Bike</h3>
                    <span>Web Designer</span>
                  </div>
                  <img class="img-fluid" src="img/mbicon.png">
                </a>
              </div>
              <div class="item research col-sm-6 col-md-4 col-lg-4 mb-4">
                <a href="research.html" class="item-wrap fancybox">
                  <div class="work-info">
                    <h3>Speech Interface</h3>
                    <span>Masters Research Project</span>
                  </div>
                  <img class="img-fluid" src="img/tcdicon.png">
                </a>
              </div>
              <div class="item design col-sm-6 col-md-4 col-lg-4 mb-4">
                <a href="gb.html" class="item-wrap fancybox">
                  <div class="work-info">
                    <h3>Groundbraker</h3>
                    <span>Mech/Elec Design</span>
                  </div>
                  <img class="img-fluid" src="img/gbicon.png">
                </a>
              </div>
              <div class="item design col-sm-6 col-md-4 col-lg-4 mb-4">
                <a href="hydra.html" class="item-wrap fancybox">
                  <div class="work-info">
                    <h3>Hydra Diagnostics</h3>
                    <span>Technical Lead</span>
                  </div>
                  <img class="img-fluid" src="img/hydrad-icon.png">
                </a>
              </div>
              <div class="item design col-sm-6 col-md-4 col-lg-4 mb-4">
                <a href="work-single.html" class="item-wrap fancybox">
                  <div class="work-info">
                    <h3>Lilongwe Water Board</h3>
                    <span>MEICA Engineer</span>
                  </div>
                  <img class="img-fluid" src="img/lwbicon.png">
                </a>
              </div>
            </div>
          </div>
        </div>



  </main>

  <footer class="footer" role="contentinfo">
    <div class="container">
      <div class="row">
        <div class="col-sm-6">
          <p class="mb-1">&copy; Copyright MyPortfolio. All Rights Reserved</p>
          <div class="credits">
            <!--
              All the links in the footer should remain intact.
              You can delete the links only if you purchased the pro version.
              Licensing information: https://bootstrapmade.com/license/
              Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=MyPortfolio
            -->
            Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
          </div>
        </div>
        <div class="col-sm-6 social text-md-right">
          <a href="https://www.linkedin.com/in/alexjshackleton/"><span class="icofont-linkedin"></span></a>
          <a href="https://github.com/shackla"><span class="icofont-github"></span></a>
        </div>
      </div>
    </div>
  </footer>

  <!-- Vendor JS Files -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/jquery/jquery-migrate.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.min.js"></script>
  <script src="vendor/easing/easing.min.js"></script>
  <script src="vendor/php-email-form/validate.js"></script>
  <script src="vendor/isotope/isotope.pkgd.min.js"></script>
  <script src="vendor/aos/aos.js"></script>
  <script src="vendor/owlcarousel/owl.carousel.min.js"></script>

  <!-- Template Main JS File -->
  <script src="js/main.js"></script>

</body>

</html>